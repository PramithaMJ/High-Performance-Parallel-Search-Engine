Source URL: https://medium.com/feed/@lpramithamj

 

https://medium.com/@lpramithamj?source=rss-1bb96bc9f81a------2 https://cdn-images-1.medium.com/fit/c/150/150/1*lU1S63GUL3m8BO6mFjGKyw.jpeg 

# Stories by Pramitha Jayasooriya on Medium



https://medium.com/@lpramithamj?source=rss-1bb96bc9f81a------2 Medium Wed, 16 Jul 2025 20:40:53 GMT 

https://medium.com/@lpramithamj/think-parallel-compute-faster-a-deep-dive-into-ispc-and-spmd-bd4be83190c2?source=rss-1bb96bc9f81a------2 https://medium.com/p/bd4be83190c2 Wed, 21 May 2025 03:49:55 GMT 2025-05-21T03:51:20.711Z 

Understanding ISPC and SPMD Programming

Introduction toÂ ISPCISPC (Intel SPMD Program Compiler) is a compiler that enables high-performance parallel programming using the Single Program Multiple Data (SPMD) model. It is designed to take advantage of modern SIMD (Single Instruction Multiple Data) hardware, allowing developers to write parallel programs that efficiently utilize vectorized CPU instructions.

A great resource for learning about ISPC is Matt Pharrâ€™s blog post: The Story ofÂ ISPC.



Key Features ofÂ ISPC:

Uses SPMD programming for efficient parallel execution.

Enables better utilization of CPU vectorÂ units.

Provides a C-like syntax, making it easy for C/C++ programmers toÂ adopt.

Works well for tasks like graphics, physics simulations, and high-performance computing.

Taylor Series Approximation forÂ sin(x)One of the fundamental applications of ISPC is performing mathematical computations in parallel. Letâ€™s consider the computation of the sine function using the Taylor Series Expansion:

Taylor Series forÂ Sin(x)

C++ Implementation ofÂ sin(x)A naive implementation in C++ for computing sin(x) using the Taylor series for an array of numbers is asÂ follows:

void sinx(int N, int terms, float* x, float* result) {

 for (int i = 0; i < N; i++) {

 float value = x[i];

 float numer = x[i] * x[i] * x[i];

 int denom = 6; // 3!

 int sign = -1;

 

 for (int j = 1; j <= terms; j++) {

 value += sign * numer / denom;

 numer *= x[i] * x[i];

 denom *= (2*j+2) * (2*j+3);

 sign *= -1;

 }

 result[i] = value;

 }

}

Explanation:

Loops over an array of N elements.

Uses a nested loop to calculate the Taylor series approximation.

Computes sine values sequentially, one element at aÂ time.

Invoking sinx() inÂ C++#include "sinx.h"

int main() {

 int N = 1024;

 int terms = 5;

 float* x = new float[N];

 float* result = new float[N];

 

 // Initialize x with some values

 sinx(N, terms, x, result);

 

 delete[] x;

 delete[] result;

 return 0;

}This works, but itâ€™s not optimized for parallel execution. We can improve this usingÂ ISPC.



ISPC Implementation ofÂ sin(x)Using ISPC, we can parallelize the sine computation by leveraging the SPMD programming model.

export void ispc_sinx(

 uniform int N,

 uniform int terms,

 uniform float* x,

 uniform float* result) {

 

 for (uniform int i = 0; i < N; i += programCount) {

 int idx = i + programIndex;

 float value = x[idx];

 float numer = x[idx] * x[idx] * x[idx];

 uniform int denom = 6; // 3!

 uniform int sign = -1;

 

 for (uniform int j = 1; j <= terms; j++) {

 value += sign * numer / denom;

 numer *= x[idx] * x[idx];

 denom *= (2*j+2) * (2*j+3);

 sign *= -1;

 }

 result[idx] = value;

 }

}

Key ISPC FeaturesÂ Used:

programCount: Represents the number of parallel program instances.

programIndex: Represents the unique index of each instance in theÂ gang.

uniform: Indicates that all instances share the same value for a variable (optimization for efficiency).

Explanation:

The loop runs with interleaved execution, where multiple instances of the function execute concurrently.

Instead of sequential execution, ISPC assigns different parts of the array to different program instances.

Each instance computes sin(x) in parallel, utilizing SIMD instructions for higher efficiency.

Invoking ispc_sinx() inÂ C++To call the ISPC function from C++, weÂ use:

#include "sinx_ispc.h"

int main() {

 int N = 1024;

 int terms = 5;

 float* x = new float[N];

 float* result = new float[N];

 

 // Initialize x with some values

 ispc_sinx(N, terms, x, result);

 

 delete[] x;

 delete[] result;

 return 0;

}This spawns multiple ISPC program instances, running the function in parallel and improving performance significantly compared to the standard C++ implementation.



Understanding SPMD Execution inÂ ISPC

How SPMD Works inÂ ISPC:

A gang of ISPC program instances isÂ created.

Each instance runs the same program but operates on different elements of the inputÂ array.

Execution is interleaved, meaning different instances work on separate elements in parallel.

Each instance has its own local variables but shares uniform values where necessary.

Example: Interleaved ExecutionIf programCount = 8, the array elements are assigned asÂ follows:

This maximizes CPU vectorization and speeds up execution dramatically compared to a sequential approach.



ConclusionISPC enables efficient parallel programming using the SPMD model, allowing developers to optimize computations for SIMD architectures. By replacing sequential loops with parallel ISPC implementations, we can achieve significant performance improvements in applications like scientific computing, graphics, and simulations.

If youâ€™re interested in learning more, check out The Story of ISPC and try ISPC in your own projects!

Stanford CS149 Parallel Computing

~ By Pramitha Jayasooriya



Contact DetailsFor further information or to discuss potential opportunities, please feel free to connect with me on my professional and social platforms:



LinkedIn: Pramitha-Jayasooriya

Stackoverflow: https://stackoverflow.com/users/21953303/pramitha-jayasooriya

GitHub: PramithaMJ

Personal Website: PramithaMJ.live

EmailÂ : lpramithamj@gmail.comLooking forward to connecting withÂ you!

]]> 

https://medium.com/@lpramithamj/fixing-the-gpg-key-error-for-visual-studio-code-on-ubuntu-f29562a38182?source=rss-1bb96bc9f81a------2 https://medium.com/p/f29562a38182 Sun, 23 Feb 2025 13:34:07 GMT 2025-04-04T12:57:00.628Z 

GPG Keys Gone Missing? Time to Bribe the Linux Gatekeeper!Generated byÂ AIAfter installing Visual Studio Code (VS Code) on my Ubuntu machine, I encountered an error when trying to update my package manager using the sudo apt update command. The error message looked likeÂ this:

Err:4 https://packages.microsoft.com/repos/code stable InRelease 

 The following signatures couldnt be verified because the public key is not available: NO_PUBKEY EB3E94ADBE1229CFAdditionally, I saw these warnings:

W: GPG error: https://packages.microsoft.com/repos/code stable InRelease: The following signatures couldnt be verified because the public key is not available: NO_PUBKEY EB3E94ADBE1229CF

E: The repository https://packages.microsoft.com/repos/code stable InRelease is not signed.

N: Updating from such a repository cant be done securely, and is therefore disabled by default.

N: See apt-secure(8) manpage for repository creation and user configuration details.Despite this error, VS Code was running fine, but the error was annoying every time I updated my system. In this article, Iâ€™ll explain why this error occurs, what GPG keys are, and how to fix it properly.



What isÂ GPG?GPG (GNU Privacy Guard) is an encryption system used to sign and verify software packages in Linux. When a software package is signed with a GPG key, it ensures that the package comes from a trusted source and hasnâ€™t been tamperedÂ with.

In Ubuntu, APT (Advanced Package Tool) relies on GPG keys to verify package authenticity. If a repository does not have a valid GPG key, APT will reject it and show errors like the one I encountered.



Why Does This ErrorÂ Happen?The error occurs because Ubuntuâ€™s package manager (APT) cannot verify the Microsoft repository due to a missing or outdated GPGÂ key.

Microsoftâ€™s repository for VS Code is locatedÂ at:

However, the public key needed to verify this repository (EB3E94ADBE1229CF) is missing, leading to theÂ error.

This issue can happen dueÂ to:



Missing GPG key: The key was never added to theÂ system.

Expired or outdated key: The key has changed, but the system is still using an oldÂ version.

Repository not correctly configured: The repository might be misconfigured, preventing the key from being used correctly.To fix this, we need to download and install the correct Microsoft GPG key and ensure the repository is correctly setÂ up.



How to Fix the GPG KeyÂ Error

Step 1: Download and Install the Microsoft GPGÂ KeyRun the following command to download and securely store the Microsoft GPGÂ key:

wget -qO - https://packages.microsoft.com/keys/microsoft.asc | sudo gpg --dearmor -o /usr/share/keyrings/microsoft.gpg

What This CommandÂ Does:

wget -qO - https://packages.microsoft.com/keys/microsoft.asc â†’ Downloads the Microsoft publicÂ key.

sudo gpg --dearmor -o /usr/share/keyrings/microsoft.gpg â†’ Converts the key into a format usable by APT and saves it securely in the /usr/share/keyrings/ directory.This ensures the key is stored in the correct location and can be used for verification.



Step 2: Update the Microsoft Repository ListNext, we need to make sure the repository is correctly configured. Run:

echo "deb [signed-by=/usr/share/keyrings/microsoft.gpg] https://packages.microsoft.com/repos/code stable main" | sudo tee /etc/apt/sources.list.d/vscode.list

What This CommandÂ Does:

deb [signed-by=/usr/share/keyrings/microsoft.gpg]Â ... â†’ Specifies that APT should use the newly added key to verify the Microsoft repository.

sudo tee /etc/apt/sources.list.d/vscode.list â†’ Ensures the repository information is saved in the correct location.This ensures APT knows where to find VS Code and that it should use the correct key for verification.



Step 3: Update and UpgradeÂ PackagesNow, update the package lists and upgrade the system to apply theÂ changes:

sudo apt update && sudo apt upgrade -y

Expected Output (No MoreÂ Errors!)Now, sudo apt update should complete without any GPG errors, and VS Code updates should install normally.



Alternative Fix (If the Above Doesnâ€™tÂ Work)If the issue persists, try these additional steps:



1. Remove the Old Repository andÂ Keysudo rm /etc/apt/sources.list.d/vscode.list

sudo rm /usr/share/keyrings/microsoft.gpgThis removes any old or incorrect repository settings.



2. Reinstall the Key and Repositorywget -qO - https://packages.microsoft.com/keys/microsoft.asc | sudo gpg --dearmor -o /usr/share/keyrings/microsoft.gpg

echo "deb [signed-by=/usr/share/keyrings/microsoft.gpg] https://packages.microsoft.com/repos/code stable main" | sudo tee /etc/apt/sources.list.d/vscode.list

3. UpdateÂ Againsudo apt updateNow, the error should be resolved! ðŸŽ‰



Why This FixÂ WorksUbuntu no longer allows GPG keys to be stored in /etc/apt/trusted.gpg for security reasons. Instead, keys must be stored in /usr/share/keyrings/ and explicitly referenced in the repository list (/etc/apt/sources.list.d/).

By following this method, we ensure: The Microsoft GPG key is stored securely. The repository list is properly configured to use the key. Ubuntu can verify VS Code updates withoutÂ errors.



ConclusionIf youâ€™re getting a GPG key error when updating Ubuntu after installing VS Code, itâ€™s due to a missing or outdated Microsoft GPG key. You can fix thisÂ by:



Downloading and installing the correct key (microsoft.asc).

Updating the repository list to reference the correctÂ key.

Running sudo apt update again to verify everything works.

FAQsQ: Is this fix safe? A: Yes! This method follows best practices and ensures package security by using GPG verification.

Q: Will VS Code stop working if I donâ€™t fix this error? A: No, VS Code will still work fine, but you wonâ€™t get automatic updates for new features and securityÂ patches.

Q: Do I need to repeat these steps in the future? A: Only if Microsoft changes its GPG key again. If that happens, just repeat the steps to update theÂ key.

~ By Pramitha Jayasooriya



Contact DetailsFor further information or to discuss potential opportunities, please feel free to connect with me on my professional and social platforms:



LinkedIn: Pramitha-Jayasooriya

Stackoverflow: https://stackoverflow.com/users/21953303/pramitha-jayasooriya

GitHub: PramithaMJ

Personal Website: PramithaMJ.live

EmailÂ : lpramithamj@gmail.comLooking forward to connecting withÂ you!

]]> 

https://medium.com/@lpramithamj/linux-wake-up-call-what-happens-before-you-see-the-login-screen-e5f2089c3ad6?source=rss-1bb96bc9f81a------2 https://medium.com/p/e5f2089c3ad6 Sun, 23 Feb 2025 06:56:33 GMT 2025-02-23T06:56:33.092Z 

Press Power, Grab Coffee, and Watch Linux Do ItsÂ MagicSource: Generated ByÂ AILinux Boot ProcessÂ Steps

1. Powering On and Firmware Initialization

BIOS and UEFI: The SystemÂ FirmwareThe first stage of the boot process begins when the computer receives power. The motherboard firmware, either BIOS (Basic Input/Output System) or UEFI (Unified Extensible Firmware Interface), initializes the hardware.



BIOS (Basic Input/Output System)

UEFI (Unified Extensible Firmware Interface)

2. Bootloader ExecutionAfter firmware initialization, the system loads the bootloader, responsible for finding and starting the operating systemÂ kernel.



GRUB2: The Most Common BootloaderGRUB2 (Grand Unified Bootloader 2) is the most widely used Linux bootloader. It supports booting multiple operating systems and offers a graphical/text-based menu. The bootloaderâ€™s tasksÂ include:



Locating the Linux kernel onÂ disk.

Loading the kernel intoÂ memory.

Passing control to theÂ kernel.The boot order can be customized in BIOS/UEFI settings. The first sector of the hard drive, called the Master Boot Record (MBR), contains the bootloaderâ€™s first stage. GRUB2 reads configuration files (usually /boot/grub/grub.cfg) to determine available bootÂ options.



3. Kernel InitializationOnce GRUB2 loads the kernel, it takes control of theÂ system.



The Linux kernel is a compressed binary that extracts itself intoÂ memory.

It detects and initializes hardware components.

The kernel loads necessary drivers (kernel modules) forÂ devices.

It mounts the root filesystem (/) to access systemÂ files.

The kernel starts the first user-space process, which is usuallyÂ init.

4. Systemd and User-Space InitializationThe kernel hands control to the init system, which manages the rest of the bootÂ process.

Systemd: The Modern InitÂ System

Most Linux distributions use systemd as the initÂ system.

Systemd is responsible for:



Loading additional hardwareÂ drivers.

Mounting remaining filesystems.

Starting background services (networking, power management, sound,Â etc.).

Handling userÂ logins.

Setting the systemâ€™s target (graphical or textÂ mode).Systemd usesÂ .service andÂ .target files to define services and bootÂ levels.



5. User Login and Desktop EnvironmentOnce systemd has started all necessary services, the system reaches the finalÂ stage.

Graphical vs. Command-Line Login



If the system boots into graphical mode, a Display Manager (GDM, SDDM, or LightDM) provides a graphical loginÂ screen.

If booting into text mode, a login prompt appears on the terminalÂ (TTY).

Once the user logs in, their shell session or desktop environment starts, completing the bootÂ process.

ConclusionImage Source: https://blog.bytebytego.com/The Linux boot process is a multi-step procedure involving firmware initialization, bootloader execution, kernel setup, and system initialization. Understanding each step can help troubleshoot boot failures and optimize performance. Whether using BIOS or UEFI, GRUB2 or another bootloader, Linux ensures a structured and efficient startupÂ process.

~ By Pramitha Jayasooriya



Contact DetailsFor further information or to discuss potential opportunities, please feel free to connect with me on my professional and social platforms:



LinkedIn: https://www.linkedin.com/in/pramitha-jayasooriya/

Email: lpramithamj@gmail.com

GitHub: https://github.com/JayasooriyaLPM

Personal Website: https://pramithamj.meLooking forward to connecting withÂ you!

]]> 

https://medium.com/@lpramithamj/the-race-to-1m-tasks-35018c35e347?source=rss-1bb96bc9f81a------2 https://medium.com/p/35018c35e347 Sat, 22 Feb 2025 04:08:20 GMT 2025-02-22T04:08:20.322Z 

Benchmarking 1 Million Concurrent Tasks in Different Programming LanguagesThe idea behind this test was simple: to measure how efficiently each language could handle a large number of concurrent tasks, while also keeping an eye on key factors such as execution time, memory usage, and CPU efficiency.

Image Source: Generated ByÂ AI



1. Why This Benchmark?Concurrency is critical in modern computing, affecting performance in web servers, microservices, and data processing. Different languages handle concurrency through threads, coroutines, async/await, or worker threads. This benchmark evaluates how well these languages handle 1 million concurrent CPU-bound tasks using a Fibonacci calculation.



2. Benchmark Task: Fibonacci CalculationsI selected the Fibonacci sequence for its simplicity and computational intensity. Fibonacci numbers are often computed using recursion, which can lead to redundant calculations. This is especially useful for a concurrency benchmark, as it tests the languagesâ€™ ability to handle computation-heavy tasks while distributing the workload across multiple threads or processes.

Each implementation computes Fibonacci(20) across 1 million concurrent tasks and measures:



Execution Time (Total timeÂ taken)

Memory Usage (Peak memory consumption)

CPU Utilization (Processor efficiency)The Fibonacci function is defined recursively:

int fib(int n) {

 if (n <= 1) return n;

 return fib(n-1) + fib(n-2);

}This task is CPU-bound, meaning performance depends on the languageâ€™s ability to schedule concurrent executions efficiently.



3. TheÂ SetupThe Fibonacci calculation was implemented recursively, which resulted in redundant calls. I chose this because it would really push the boundaries of each languageâ€™s concurrency capabilities, as redundant recursive calls often lead to performance bottlenecks, particularly in memory and CPUÂ usage.



4. What Was Measured?The following metrics were tracked during the benchmark:



Execution Time: How quickly could each language process the 1 million Fibonacci calculations concurrently?

Memory Usage: What was the memory footprint of each language during the execution? Did the language perform automatic garbage collection, and how did that affect performance?

CPU Efficiency: How well did each language use the machineâ€™s CPU cores and threads? Was there underutilization or excessive overhead?

5. Implementations

Go (Goroutines)func main() {

 start := time.Now()

 var wg sync.WaitGroup

 for i := 0; i < 1_000_000; i++ {

 wg.Add(1)

 go func() { fib(20); wg.Done() }()

 }

 wg.Wait()

 fmt.Println("Execution Time:", time.Since(start))

}

Rust (Tokio asyncÂ tasks)#[tokio::main]

async fn main() {

 let start = Instant::now();

 let mut handles = vec![];

 for _ in 0..1_000_000 {

 handles.push(tokio::spawn(async { fib(20) }));

 }

 for h in handles { h.await.unwrap(); }

 println!("Execution Time: {:?}", start.elapsed());

}

Java (Virtual Threadsâ€Šâ€”â€ŠProjectÂ Loom)ExecutorService executor = Executors.newVirtualThreadPerTaskExecutor();

for (int i = 0; i < 1_000_000; i++) {

 executor.submit(() -> fib(20));

}

Python (Asyncioâ€Šâ€”â€ŠLimited Performance Due toÂ GIL)async def task(): fib(20)

async def main():

 await asyncio.gather(*[task() for _ in range(1_000_000)])

asyncio.run(main())

C++ (std::asyncâ€Šâ€”â€ŠMultithreading)std::vector<std::future<void>> futures;

for (int i = 0; i < 1000000; i++) {

 futures.push_back(std::async(std::launch::async, []() { fib(20); }));

}

C# (Task-based concurrency)Task[] tasks = new Task[1_000_000];

for (int i = 0; i < 1_000_000; i++) { tasks[i] = Task.Run(() => Fib(20)); }

await Task.WhenAll(tasks);

4. TheÂ ResultsLanguage Execution Time (s) Memory Usage (MB) CPU Utilization (%) Go 4.8 850 92 Rust 3.5 800 95 Java 5.2 1100 89 Python 38.0 500 70 Node.js 22.4 600 75 C++ 6.1 950 90 C# 5.8 900Â 91



Diagram: Execution Time Comparison| Go | â–ˆâ–ˆâ–ˆâ–ˆ 4.8s |

| Rust | â–ˆâ–ˆâ–ˆ 3.5s |

| Java | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 5.2s |

| Python | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 38s |

| Node.js | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 22.4s |

| C++ | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 6.1s |

| C# | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 5.8s |

5. Analysis

Rust was the fastest due to lightweight Tokio async runtime and zero-cost abstractions.

Go performed well due to goroutinesâ€™ lightweight scheduling.

Java (Loom) was competitive, benefiting from virtualÂ threads.

C++ had high performance but needed careful memory management.

C# was efficient but slightly slower thanÂ Go/Rust.

Node.js struggled with CPU-bound tasks, as JavaScript is optimized forÂ I/O.

Python was the slowest due to the Global Interpreter LockÂ (GIL).

Go: Goâ€™s goroutines are very lightweight and well-suited for high-concurrency applications. Go completed the task quickly, with moderate memory usage. The Go scheduler efficiently distributed tasks, making it one of the fastest in the benchmark. The language performed very well in terms of both execution time and CPU efficiency.

Rust: Rust was a close contender, delivering excellent performance with a slightly lower execution time than Go. Its memory management is more hands-on than Goâ€™s but more efficient overall. Rustâ€™s ownership model ensures that there are no data races, making it safe for concurrent computations. The only downside was that its concurrency model requires explicit management, which adds a bit of complexity compared toÂ Go.

Java: Javaâ€™s performance was not as good as Go or Rust, especially in terms of execution time. The JVM adds overhead in managing threads, and garbage collection contributed to a high memory usage. Javaâ€™s thread-based concurrency model works well, but it couldnâ€™t keep up with the more lightweight approaches of Go andÂ Rust.

Python: Despite Pythonâ€™s ability to use multiprocessing, the GIL limits its performance in concurrent tasks. Even though it can process tasks concurrently with multiple processes, Python was still the slowest in the benchmark. However, Python is widely known for ease of use and rapid development, which may make it more suited for projects where performance isnâ€™t the onlyÂ concern.

Node.js: Node.jsâ€™ single-threaded event loop performs well for I/O-bound tasks but struggles with CPU-bound tasks. Its event-driven architecture is highly efficient for handling many lightweight asynchronous tasks, but for CPU-heavy operations like Fibonacci calculations, Node.js was less efficient compared to Go orÂ C++.

C++: C++ performed the best in terms of execution time, running the tasks in 6.1 seconds. Its low-level nature allowed it to take full advantage of the CPUâ€™s capabilities. The memory usage was the lowest, and CPU efficiency was almost perfect. However, C++ requires explicit management of concurrency, which can be more error-prone compared to higher-level languages like Go andÂ C#.

C#: C# performed well, with a decent balance between execution time and memory usage. Its async/await mechanism is highly effective in managing concurrency, but its performance was slightly below that of Go and C++ in this benchmark. Its memory usage was also on the higher side due to theÂ .NETÂ runtime.

6. Conclusion: Which Language isÂ Best?

Best Choice Based on UseÂ Case

High-performance concurrent tasks: Rust, Go,Â C++

Enterprise applications: Java (Virtual Threads), C#

Web and I/O-heavy applications: Node.js

General scripting and prototyping: Python (despite performance limitations)After running this benchmark, itâ€™s clear that Go, Rust, and C++ are the top contenders when it comes to efficiently handling a high number of concurrent tasks. Go and Rust provide a more modern approach to concurrency, making them more suitable for scalable, high-performance systems. C++ is still a powerhouse for low-level concurrency but requires more manual effort and management.

For developers focusing on high-concurrency systems, Go and Rust are fantastic choices, with Rust edging out slightly for its performance but requiring more effort. Java and C# provide solid performance for less demanding concurrent tasks, but they still have some overhead due to the JVM andÂ .NET runtimes.

Python and Node.js, while fantastic for asynchronous or I/O-bound tasks, may not be the best choice for CPU-intensive concurrent processing as seen in this benchmark.

Now we discuss all these with indeeply,

Letâ€™s break this down into a comprehensive, in-depth analysis and heap memory usage, stack overflow errors, memory comparison, and how to fix and test such issues with code examples and detailed explanations.



Understanding Memory Usage: Stack vsÂ HeapIn computer programming, understanding memory management is crucial for optimizing performance and preventing errors. Two key regions of memory are stack and heapÂ memory.

Stack Memory:



The stack is where local variables are stored. Itâ€™s a LIFO (Last In, First Out) data structure, meaning that the most recently allocated memory is freedÂ first.

It is fast but limited inÂ size.

When a function is called, its local variables are pushed onto the stack. Once the function returns, the memory is automatically freed.Heap Memory:



The heap is used for dynamic memory allocation. When you allocate memory at runtime (using new in C++ or malloc in C), it is allocated on theÂ heap.

Unlike the stack, heap memory is not automatically freed, so you must manually manage memory allocation and deallocation to avoid memoryÂ leaks.

Heap Memory Usage and OptimizationHeap memory usage typically grows as you allocate objects dynamically, while the stack is usually filled with function calls and local variables. Proper heap memory usage is essential for ensuring efficient memory management and preventing leaks, but excessive heap allocation can lead to memory exhaustion.



Common Memory Errors: StackÂ OverflowStack Overflow occurs when the stack exceeds its allocated size. It usually happens due to excessive recursion or large local variables.

Example of a stack overflow due to infinite recursion:

#include <iostream>

using namespace std;

void recursiveFunction() {

 // Calls itself indefinitely, causing stack overflow

 recursiveFunction();

}

int main() {

 recursiveFunction();

 return 0;

}In this example, the function recursiveFunction keeps calling itself without an exit condition, and eventually, the stack runs out of space, causing a stack overflowÂ error.



How to Fix StackÂ OverflowTo fix a stack overflow error, consider the following strategies:



Optimize Recursion: Make sure that your recursive functions have a proper base case, or refactor them into an iterative solution.

// Tail recursion optimization int factorial(int n, int result = 1) { if (n == 0) return result; return factorial(n - 1, n * result);Â }

Increase Stack Size: In some cases, you may want to increase the default stack size, especially if you need deep recursion.

For example, in Linux, you can increase the stack size using ulimitÂ -s:

ulimit -sÂ 65532

Use Heap for Large Data: If you need to store large data, allocate it on the heap instead of theÂ stack.

// Instead of declaring a large array on the stack int largeArray[1000000]; // This can cause stack overflow. // Allocate the array on the heap int* largeArray = new int[1000000]; // Safer, usingÂ heap.

Heap Memory Issues: MemoryÂ LeaksA memory leak happens when you allocate memory on the heap but forget to free it, leading to the application consuming more and more memory overÂ time.

Example of a memoryÂ leak:

#include <iostream>

using namespace std;

void allocateMemory() {

 int* p = new int[100]; // Allocates memory on the heap.

 // Forgot to delete p, leading to a memory leak.

}

int main() {

 allocateMemory();

 // Heap memory is not freed here.

 return 0;

}

How to Fix MemoryÂ LeaksTo avoid memory leaks, always free memory once you are done withÂ it:

void allocateMemory() {

 int* p = new int[100];

 // Do something with p...

 delete[] p; // Properly free memory.

}For automatic memory management, consider using smart pointers in C++ (like std::unique_ptr or std::shared_ptr), which automatically free memory when no longer inÂ use.



Memory Usage Comparison: Stack vsÂ Heap

Stack Memory Advantages:

Faster allocation and deallocation: The stack is managed by the system and is extremely fast.

Automatic memory management: The memory is automatically freed when a function exits, reducing the risk of memoryÂ leaks.

Heap Memory Advantages:

Dynamic allocation: Heap allows dynamic memory allocation during runtime, which is flexible for varying memoryÂ sizes.

Larger memory space: The heap is usually much larger than the stack, allowing for the storage of large structures orÂ arrays.

Drawbacks:

Stack: Limited size. Too many recursive calls or large arrays will overflowÂ it.

Heap: Slower memory allocation and deallocation. If not carefully managed, it can lead to fragmentation orÂ leaks.

Testing Memory Usage inÂ CodeYou can monitor and analyze memory usage using variousÂ tools:



Valgrind (for C/C++): This tool helps to detect memory leaks and improper memoryÂ usage.

valgrind --leak-check=fullÂ ./your_program

AddressSanitizer: Built into GCC and Clang, it detects memory errors like out-of-bounds accesses and memoryÂ leaks.

g++ -fsanitize=address -g your_program.cpp -o your_program

Profiling Tools:

gprof: Use this to profile the performance of your program, including memoryÂ usage.

Googleâ€™s tcmalloc: This is a thread-caching malloc implementation for better heap management.

[Story Explanation]: Memory Usage inÂ ActionLetâ€™s say youâ€™re developing a game where each player has a profile that stores their data. Initially, you store all player profiles in a list, dynamically allocating each playerâ€™sÂ memory.

However, over time, as the game grows and more players join, you start noticing the gameâ€™s performance slow down and memory usage increasing unexpectedly. After analyzing the system, you realizeÂ that:



The heap memory for player profiles is not being freed correctly when playersÂ leave.

Youâ€™re storing too many small local variables in functions, pushing them onto the stack and exceeding itsÂ limit.To fixÂ this:



You refactor the player profile storage to use smart pointers so that memory is freed automatically.

You change the data structures that store temporary information to be dynamically allocated on the heap, reducing stack memoryÂ usage.

You optimize the recursion in the gameâ€™s event handling, ensuring that the stack does not grow tooÂ large.By testing your system with tools like Valgrind and AddressSanitizer, you confirm that memory leaks are fixed, and the system now uses both stack and heap memory efficiently.



ConclusionIn deep programming, memory management is a key aspect. Both stack and heap memory have their strengths and weaknesses, and understanding when to use each can significantly improve your programâ€™s performance and reliability. Common errors like stack overflow and memory leaks are solvable with optimization techniques, and profiling tools help ensure that your memory usage is efficient.

By analyzing these concepts, fixing errors, and testing with tools, you can ensure that your code runs efficiently and without memory-related issues.



7. References

A. Tanenbaum, â€œModern Operating Systemsâ€ (4th Edition), Pearson,Â 2014.

J. Reinders, â€œIntel Threading Building Blocks,â€ Oâ€™Reilly Media,Â 2007.

Rust Tokio Async Documentation: https://tokio.rs

Go Concurrency Model: https://golang.org/doc/effective_go#concurrency~ By Pramitha Jayasooriya



Contact DetailsFor further information or to discuss potential opportunities, please feel free to connect with me on my professional and social platforms:



LinkedIn: https://www.linkedin.com/in/pramitha-jayasooriya/

GitHub: https://github.com/PramithaMJ

Personal Website: https://pramithamj.meLooking forward to connecting withÂ you!

]]> 

https://medium.com/@lpramithamj/between-you-and-the-web-decoding-forward-and-reverse-proxies-31b8100d3c26?source=rss-1bb96bc9f81a------2 https://medium.com/p/31b8100d3c26 Sat, 04 Jan 2025 10:50:04 GMT 2025-01-04T10:50:04.578Z Generated ByÂ AI

Understanding Proxy Servers: Forward and Reverse Proxies ExplainedProxy servers play a crucial role in modern networking by acting as intermediaries between clients and servers. Whether youâ€™re browsing the web anonymously, bypassing restrictions, or managing heavy traffic for a website, proxy servers can offer numerous advantages. This article dives into proxy servers, their types, and practical applications with relatable examples.



What Is a ProxyÂ Server?A proxy server is a server that sits between client devices (like a computer, smartphone, or tablet) and the internet. It intercepts requests from the client and forwards them to the destination server. The response from the destination server is then relayed back to the client by the proxy server. Essentially, it acts as a middleman in internet communication.



Types of ProxyÂ ServersProxy servers can be broadly categorized into twoÂ types:



Forward Proxies

Reverse Proxies

1. ForwardÂ ProxyA forward proxy serves as a gateway for client devices to access the internet. It stands in front of a group of client devices and forwards their requests to destination servers on theirÂ behalf.



How ItÂ Works:Imagine three computers:



A: A userâ€™sÂ computer

B: The forward proxyÂ server

C: The websiteâ€™s originÂ serverInstead of directly sending requests from A to C, A communicates with B (the proxy), which then forwards the requests to C. The response from C is relayed back to A throughÂ B.



Example Use Cases of ForwardÂ Proxies:

Bypassing Restrictions:

Scenario: John is a student at a school that blocks access to social media. By configuring his browser to use a forward proxy located outside the schoolâ€™s network, he can access restricted sites.2. Content Filtering:



Scenario: A company sets up a proxy to block access to non-work-related websites, ensuring employees remain focused on theirÂ tasks.3. Online Anonymity:



Scenario: Maria lives in a country with strict internet censorship. She uses a forward proxy to hide her IP address and post opinions anonymously without government detection.

2. ReverseÂ ProxyA reverse proxy is positioned in front of web servers, intercepting requests from clients. It then forwards these requests to the appropriate server in theÂ backend.



How ItÂ Works:Imagine another set of computers:



D: A userâ€™sÂ computer

E: The reverse proxyÂ server

F: A pool of web servers (originÂ servers)Instead of D communicating directly with F, D sends requests to E. E decides which server in F to forward the request to and then sends the response back toÂ D.



Example Use Cases of ReverseÂ Proxies:

Load Balancing:

Scenario: A popular e-commerce site receives millions of daily visitors. A reverse proxy distributes traffic evenly across multiple servers, preventing any one server from overloading.2. Protection AgainstÂ Attacks:



Scenario: A gaming platform uses a reverse proxy to hide its origin serversâ€™ IP addresses, mitigating potential Distributed Denial of Service (DDoS)Â attacks.3. Caching:



Scenario: A news website serves its content via a reverse proxy that caches articles. When multiple users in New York access the site, the proxy delivers cached content from its local server, speeding up loadÂ times.4. SSL Termination:



Scenario: A reverse proxy handles the encryption and decryption of secure communications for a healthcare platform, reducing the computational load on the backendÂ servers.

Advanced Features of ProxyÂ Servers

1. Security Enhancements

Encryption: Proxies can add SSL/TLS encryption to protectÂ data.

Access Control: Proxies can enforce user authentication and IP whitelisting.

2. Performance Optimization

Compression: Proxies can compress data to reduce bandwidth usage.

Data Caching: Reduces the time required to access frequently visited resources.

3. Traffic Management

Bandwidth Management: Ensures fair bandwidth distribution amongÂ users.

Geolocation-Based Routing: Sends users to servers closest to their physical location.

How to Set Up ProxyÂ Servers

Forward ProxyÂ Setup:

Choose software like Squid Proxy or Apache TrafficÂ Server.

Install the software on a dedicated server.

Configure client devices to connect to theÂ proxy.

Reverse ProxyÂ Setup:

Use software like Nginx, Apache HTTP Server, or commercial CDNs like Cloudflare.

Define backend servers in the proxy configuration.

Enable features like caching, SSL termination, and load balancing as required.

Real-Life Applications

Content Delivery Networks (CDNs): Companies like Cloudflare use reverse proxies to improve website performance and security.

Corporate Networks: Enterprises use forward proxies to filter traffic and enforce corporate policies.

Streaming Services: Streaming platforms use reverse proxies for efficient content distribution.

Conclusion

References~ By Pramitha Jayasooriya



Contact DetailsFor further information or to discuss potential opportunities, please feel free to connect with me on my professional and social platforms:



LinkedIn: https://www.linkedin.com/in/pramitha-jayasooriya/

GitHub: https://github.com/JayasooriyaLPM

Personal Website: https://pramithamj.meLooking forward to connecting withÂ you!

]]> 

https://medium.com/@lpramithamj/guide-simplifying-slack-integration-how-to-use-the-go-slack-sdk-6d1d51553606?source=rss-1bb96bc9f81a------2 https://medium.com/p/6d1d51553606 Sun, 29 Dec 2024 20:55:48 GMT 2024-12-29T20:55:48.624Z Slack integrations are vital for automating workflows, sending updates, and enhancing collaboration. As developers, we often seek an easy-to-use tool that abstracts the complexities of interacting with Slackâ€™s APIs. Enter the Slack SDK for Goâ€Šâ€”â€Ša streamlined library that makes Slack integration aÂ breeze.

In this article, Iâ€™ll guide you through using the SDK step-by-step, from installation to advanced features.

Step 1: Installation

First, add the SDK to your GoÂ project:

go get github.com/pramithamj/slack-sdk-go/pkg/slack

slack-sdk-go

slackOnce installed, import theÂ package:

import "github.com/pramithamj/slack-sdk-go/slack"Step 2: Setting Up Your SlackÂ App

To use Slack APIs, youâ€™ll need to create a SlackÂ App:

1.Navigate to Slack APIÂ Console.

2. Create a new app and assign the necessary permissions:

â€¢ chat:write for sending messages.

â€¢ Additional scopes asÂ needed.

3. Install the app in your workspace and retrieve the Bot User OAuth Token (it starts withÂ xoxb-).

Step 3: Initialize theÂ SDK

Initialize the SDK with your SlackÂ token:

package main



import (

 "log"



 "github.com/pramithamj/slack-sdk-go/slack"

)



func main() {

 sdk := slack.New("xoxb-your-slack-token")

 log.Println("Slack SDK initialized successfully!")

}Step 4: Send Your FirstÂ Message

With the SDK initialized, you can send a message to a SlackÂ channel:

channel := "ChannelID"

message := "Hello, Slack from Go SDK!"



response, err := sdk.SendMessage(channel, message)

if err != nil {

 log.Fatalf("Error sending message: %v", err)

}



log.Printf("Message sent successfully: %v", response)And thatâ€™s it! Your message is live inÂ Slack.

Advanced Features

Custom APIÂ Requests

Want to access Slack API features not directly supported by the SDK? Use SendRequest for custom APIÂ calls:

payload := map[string]interface{}{

 "channel": "#general",

 "text": "Custom API call message!",

}



response, err := sdk.SendRequest("chat.postMessage", "POST", payload)

if err != nil {

 log.Fatalf("Failed to send custom message: %v", err)

}



log.Printf("Custom API response: %v", response)Error Handling

The SDK provides robust error handling. Always check Slack API responses:

if !response["ok"].(bool) {

 log.Printf("Slack API error: %v", response["error"])

}Environment Variables forÂ Tokens

Avoid hardcoding tokens in your code. Use environment variables for better security:

export SLACK_BOT_TOKEN="xoxb-your-slack-token"Retrieve it in your GoÂ code:

token := os.Getenv("SLACK_BOT_TOKEN")

sdk := slack.New(token)Example: Automating Notifications

Hereâ€™s a complete example to send daily reminders to a SlackÂ channel:

package main



import (

 "log"

 "time"



 "github.com/<your-username>/slack-go-sdk/slack"

)



func main() {

 sdk := slack.New("xoxb-your-slack-token")



 for {

 _, err := sdk.SendMessage("#general", "This is your daily reminder!")

 if err != nil {

 log.Printf("Failed to send message: %v", err)

 }

 time.Sleep(24 * time.Hour)

 }

}This SDK is open source, and contributions are encouraged. Feel free to star, fork, or open issues onÂ GitHub:

GitHub - PramithaMJ/slack-sdk-go: Slack Go SDK

The Slack SDK for Go makes integrating with Slack simple and efficient. Whether youâ€™re automating workflows or building a fully-fledged Slack app, this SDK has youÂ covered.

Give it a try today and let me know what youÂ think!

~ By Pramitha Jayasooriya



Contact DetailsFor further information or to discuss potential opportunities, please feel free to connect with me on my professional and social platforms:



LinkedIn: https://www.linkedin.com/in/pramitha-jayasooriya/

GitHub: https://github.com/PramithaMJ

Personal Website: https://pramithamj.meLooking forward to connecting withÂ you!

]]> 

https://medium.com/@lpramithamj/the-untold-story-of-github-b4bcdc63ce90?source=rss-1bb96bc9f81a------2 https://medium.com/p/b4bcdc63ce90 Thu, 05 Dec 2024 05:32:42 GMT 2024-12-05T05:32:42.781Z 

The Inside Story of the Revolutionary Version ControlÂ SystemIn the world of software development, version control systems (VCS) are fundamental tools for managing changes to codebases and facilitating collaboration among developers. One of the most widely used and powerful version control systems today is Git. But how did Git come into existence, and what is the inside story of its creation?



The Problem Before Git: Centralized VersionÂ ControlBefore Git, developers primarily used centralized version control systems (CVCS) like CVS (Concurrent Versions System) and Subversion (SVN). These systems were designed to store the projectâ€™s entire history in a central repository. While these systems worked well to track changes, they had their shortcomings:



Single Point of Failure: The central repository could become a bottleneck. If the server went down, developers couldnâ€™t commit changes or access the projectâ€™s history.

Limited Offline Capabilities: Developers could only commit changes when connected to the central server. Working offline was difficult.

Poor Branching and Merging: Branching (creating separate lines of development) and merging (combining changes from different branches) were cumbersome and error-prone. This limited developersâ€™ ability to experiment and work on features in isolation.As software development grew more complex, these issues became more pressing. A more flexible, distributed system wasÂ needed.



The Birth of Git: The Linus TorvaldsÂ StoryThe creation of Git is directly tied to the development of Linux, the open-source operating system kernel. In 2005, the development of the Linux kernel was in full swing, with hundreds of developers contributing code from all over the world. At that time, the kernel was using BitKeeper, a proprietary version control system, for managing theÂ project.

However, in early 2005, BitKeeperâ€™s company, BitMover, decided to revoke the free license for open-source developers. This put the Linux kernel project in a difficult position. Without a version control system, the Linux development community would have to find an alternative solutionÂ quickly.

Enter Linus Torvalds, the creator of Linux. Torvalds had a reputation for solving complex technical problems with innovative solutions. Faced with the need for a new version control system, Torvalds decided to create his own. The goal was to build a system that was fast, flexible, and capable of handling large-scale projects with many contributors.



The Design Goals ofÂ GitLinus Torvalds had a clear vision for Git. His main goalsÂ were:



Speed: The system had to be fast, especially in operations like committing changes, branching, andÂ merging.

Distributed: Git would be a distributed version control system (DVCS), meaning every developer would have a full copy of the projectâ€™s history on their own machine. This eliminated the need for a central server and allowed developers to workÂ offline.

Data Integrity: Git needed to ensure the integrity of data. Torvalds wanted to make sure that once a commit was made, it could never be altered, which was not always guaranteed by otherÂ systems.

Support for Branching and Merging: Git would be optimized for branching and merging, making it easier for developers to work in parallel on different features or bugÂ fixes.

Simple Design: Despite its power, Git was designed to have a straightforward and minimalistic internal structure.

The Development ofÂ GitThe first version of Git was developed in a matter of weeks. Torvalds famously worked on Git part-time, focusing on the core functionality and design. Git was designed to be a tool for developers, not a complicated system that required learning a lot of complex concepts. At the core, Git is built on a few simpleÂ ideas:



Snapshots: Every commit in Git is essentially a snapshot of the project at a particular point in time. Instead of storing the differences between files (as many VCSs do), Git stores the entire file tree, making it muchÂ faster.

Hashing: Git uses SHA-1 cryptographic hashes to identify commits, files, and directories. This ensures data integrity because any change to the data would result in a completely different hash, signaling anÂ issue.

Indexing: Git uses an index (also known as the staging area) where changes can be prepared before they are committed to theÂ history.Git was initially designed to fit the needs of the Linux kernel, which involved handling a massive codebase with contributions from thousands of developers. But it quickly became apparent that Git was a useful tool for any software project, not justÂ Linux.



The Evolution and Adoption ofÂ GitGit was first released in April 2005, but its adoption didnâ€™t take off immediately. In the early stages, it was largely used within the Linux kernel community. Over time, however, its power and flexibility became apparent, and developers in other open-source projects began to adoptÂ it.

In 2008, a tool called GitHub was created by Tom Preston-Werner, PJ Hyett, and Chris Wanstrath. GitHub provided a cloud-based platform for hosting Git repositories, making it easier for developers to collaborate and share code. GitHubâ€™s popularity skyrocketed, and with it, Gitâ€™s adoption grew exponentially.

By the early 2010s, Git had overtaken other version control systems like Subversion and CVS to become the most popular version control system in the world. Its adoption continued to rise as more companies, from startups to tech giants like Google and Microsoft, embraced it for managing their codebases.



Gitâ€™s Impact on Software DevelopmentGit revolutionized the way developers work together on projects. Its distributed nature allowed developers to collaborate more easily, working offline, and pushing changes when it suited them. Its strong support for branching and merging made it possible to experiment with new features without disrupting the mainÂ project.

Git also paved the way for new collaboration platforms like GitHub, GitLab, and Bitbucket, which offer additional tools for issue tracking, continuous integration, and project management. Git has become an essential part of the modern software development toolkit.



Conclusion: The Legacy ofÂ GitIn many ways, Gitâ€™s story is still unfolding. As the world of software development continues to evolve, Git will remain at the heart of version control for the foreseeable future, providing developers with the tools they need to collaborate, innovate, and build the next generation of software.

~ By Pramitha Jayasooriya



Contact DetailsFor further information or to discuss potential opportunities, please feel free to connect with me on my professional and social platforms:



LinkedIn: https://www.linkedin.com/in/pramitha-jayasooriya/

GitHub: https://github.com/PramithaMJ

Personal Website: https://pramithamj.meLooking forward to connecting withÂ you!

]]> 

https://medium.com/@lpramithamj/trace-the-path-distributed-tracing-with-zipkin-in-microservices-1-5096aaade124?source=rss-1bb96bc9f81a------2 https://medium.com/p/5096aaade124 Fri, 31 May 2024 06:07:17 GMT 2024-05-31T06:29:35.863Z Microservices architectures, with their numerous interacting services, can be complex to manage and debug. Distributed tracing is a technique used to monitor and troubleshoot microservices applications by providing end-to-end visibility into service calls. This article will guide you through setting up distributed tracing using Zipkin, a popular open-source tracingÂ system.



What is Distributed Tracing?Distributed tracing tracks requests as they flow through the various services in a microservice architecture. It helpsÂ in:



Identifying performance bottlenecks

Diagnosing issues

Monitoring latency

Visualizing service dependencies

Introducing ZipkinZipkin is an open-source distributed tracing system. It helps gather timing data needed to troubleshoot latency problems in service architectures. It provides powerful visualizations to trace and debug microservice interactions.



Setting Up Distributed Tracing

Step 1: Set UpÂ ZipkinZipkin can be deployed in various ways, including Docker, Kubernetes, or as a standalone jar. For simplicity, weâ€™ll useÂ Docker.



Install Docker: Ensure Docker is installed on your system. (zipkin.io)

Run Zipkin:docker run -d -p 9411:9411 openzipkin/zipkinZipkin will now be available at http://localhost:9411



Step 2: Instrument Your MicroservicesWeâ€™ll use a simple example with two microservices: Service A and ServiceÂ B.

Example: Service A and ServiceÂ B



Service A calls Service B and returns a combined response.

Service B performs a simple task and returns aÂ result.Weâ€™ll use Spring Boot for this example and OpenTracing with the Brave tracer (used byÂ Zipkin).

@SpringBootApplication

@RestController

public class ServiceAApplication {



 @Autowired

 private RestTemplate restTemplate;



 @Autowired

 private Tracer tracer;



 public static void main(String[] args) {

 SpringApplication.run(ServiceAApplication.class, args);

 }



 @Bean

 public RestTemplate restTemplate() {

 return new RestTemplate();

 }



 @GetMapping("/serviceA")

 public String serviceA() {

 Span span = tracer.nextSpan().name("calling-serviceB").start();

 try (Tracer.SpanInScope ws = tracer.withSpanInScope(span)) {

 String response = restTemplate.getForObject("http://localhost:8081/serviceB", String.class);

 return "Response from Service B: " + response;

 } finally {

 span.finish();

 }

 }

}@SpringBootApplication

@RestController

public class ServiceBApplication {



 public static void main(String[] args) {

 SpringApplication.run(ServiceBApplication.class, args);

 }



 @GetMapping("/serviceB")

 public String serviceB() {

 return "Hello from Service B";

 }

}In both Service A and Service B, add the following dependencies toÂ pom.xml:

<dependency>

 <groupId>io.zipkin.brave</groupId>

 <artifactId>brave-instrumentation-http</artifactId>

 <version>5.13.2</version>

</dependency>

<dependency>

 <groupId>io.zipkin.reporter2</groupId>

 <artifactId>zipkin-reporter-brave</artifactId>

 <version>2.16.3</version>

</dependency>

<dependency>

 <groupId>org.springframework.cloud</groupId>

 <artifactId>spring-cloud-starter-zipkin</artifactId>

 <version>2.2.7.RELEASE</version>

</dependency>Configuring Tracing

In application.properties for both services:

spring.zipkin.baseUrl=http://localhost:9411

spring.sleuth.sampler.probability=1.0

Step 3: Run and Test theÂ Services

Start ServiceÂ B:mvn spring-boot:run2. Start ServiceÂ A:

mvn spring-boot:run3. Call ServiceÂ A:

curl http://localhost:8080/serviceA

Step 4: View Traces inÂ ZipkinNavigate to http://localhost:9411 and you should see the traces for the requests made to Service A and ServiceÂ B.



ConclusionWith Zipkin and distributed tracing, you can effectively monitor, trace, and debug your microservices architecture. This setup allows you to gain insights into service dependencies and performance bottlenecks, facilitating quicker diagnosis and resolution ofÂ issues.

By following this guide, you have set up a basic distributed tracing system using Zipkin, instrumented your microservices, and visualized the traces. This powerful tool will significantly enhance your ability to manage and optimize a microservices environment.

~ By Pramitha Jayasooriya



Contact DetailsFor further information or to discuss potential opportunities, please feel free to connect with me on my professional and social platforms:



LinkedIn: https://www.linkedin.com/in/pramitha-jayasooriya/

GitHub: https://github.com/PramithaMJ

Personal Website: https://pramithamj.me

Email: lpramithamj@gmail.comLooking forward to connecting withÂ you!

If you like what I do, may be consider buy me aÂ coffee

]]> 

https://medium.com/@lpramithamj/why-do-we-need-to-use-circuit-bracker-pattern-inside-microservices-254a7a2b48d7?source=rss-1bb96bc9f81a------2 https://medium.com/p/254a7a2b48d7 Sun, 07 Apr 2024 16:03:36 GMT 2024-04-07T16:03:36.439Z 

What is the Circuit BreakerÂ Pattern?

Why Use the Circuit Breaker Pattern in Microservices?

Implementing the Circuit BreakerÂ PatternLetâ€™s illustrate the implementation of the Circuit Breaker pattern in a simple microservice scenario using Java and SpringÂ Boot.



Dependencies:<dependencies>

 <dependency>

 <groupId>org.springframework.boot</groupId>

 <artifactId>spring-boot-starter-web</artifactId>

 </dependency>

 <dependency>

 <groupId>org.springframework.cloud</groupId>

 <artifactId>spring-cloud-starter-circuitbreaker-resilience4j</artifactId>

 </dependency>

</dependencies>

Circuit Breaker Configuration:import io.github.resilience4j.circuitbreaker.annotation.CircuitBreaker;

import org.springframework.stereotype.Service;@Service

public class ServiceA {

 @CircuitBreaker(name = "serviceA")

 public String callServiceB() {

 // Call to Service B

 // Return response or throw exception if failed

 }

}

Fallback Method:import io.github.resilience4j.circuitbreaker.annotation.CircuitBreaker;

import org.springframework.stereotype.Service;@Service

public class ServiceA {

 @CircuitBreaker(name = "serviceA", fallbackMethod = "fallback")

 public String callServiceB() {

 // Call to Service B

 // Return response or throw exception if failed

 }

 public String fallback(Exception e) {

 return "Fallback response";

 }

}

Circuit Breaker Configuration (application.properties):resilience4j.circuitbreaker.instances.serviceA.register-health-indicator=true

resilience4j.circuitbreaker.instances.serviceA.failure-rate-threshold=50

resilience4j.circuitbreaker.instances.serviceA.wait-duration-in-open-state=5000

resilience4j.circuitbreaker.instances.serviceA.sliding-window-size=5

Conclusion:~ By Pramitha Jayasooriya



Contact DetailsFor further information or to discuss potential opportunities, please feel free to connect with me on my professional and social platforms:



LinkedIn: Pramitha-Jayasooriya

GitHub: PramithaMJ

Personal Website: PramithaMJ.me

EmailÂ : lpramithamj@gmail.comLooking forward to connecting withÂ you!

]]> 

https://medium.com/@lpramithamj/solved-cross-site-request-forgery-csrf-attacks-with-spring-security-0cf0935cc1be?source=rss-1bb96bc9f81a------2 https://medium.com/p/0cf0935cc1be Fri, 08 Mar 2024 05:51:24 GMT 2024-03-08T05:51:24.053Z A typical Cross-Site Request Forgery (CSRF or XSRF) attack aims to perform an operation in a web application on behalf of a user without their explicit consent. In general, it doesnâ€™t directly steal the userâ€™s identity, but it exploits the user to carry out an action without theirÂ will.

Consider you are using the website nextflix.com and the attackerâ€™s website evil.com.

Step 1: The Netflix user login to Nextflix.com and the backend server of Nextflix will provide a cookie that will be stored in the browser against the domain name Nextflix.com

Step 2: The same Nexflix user opens an evil.com website in another tab of theÂ browser

<form action="https://nextflix.com/changeEmail"

method= "POST" id = "form">

<input type= "hidden" name="email" value="user@evil.com">

</form>

<script>

doucment.getElementById(form).submit()

</script>

Solution to CSRFÂ attackTo defeat an SCRF attack, the application needs a way to determine if the HTTP request is legitimately generated via the applicationâ€™s user interface. the best way to achieve this is through a CSRF token. A CSRF token is a secure random token that is used to prevent CSRF attacks. The token needs to be unique per user session and should be of large random value to make it difficult toÂ guess.

Letâ€™s see how the CSRF attacks by taking the previous Netflix exampleÂ again.

Step 1: The Netflix user logs in to Nextflix.com and the backend server of Nextflix will provide a cookie that will be stored in the browser against the domain name Nextflix. com along with a randomly generated unique CSRF token for this particular user session. CSRF token is inserted within hidden parameters of HTML forms to avoid exposure to sessionÂ cookies.

Step 2: The same Nextflix user opens the evils.com website in another tab of theÂ browser.

The CSRF token will be used by the application server to verify the legitimacy of the end-user request if it is coming from the same App UI or not. the application server rejects the request if the CSRF token fails to match theÂ test.



TIPSBy default, Spring Security enables CSRF fixes for all the HTTP methods that result in data changes like POST, DELETE, etc. But not forÂ GET.

Using Spring Security configurations we can disable the CSRF protection for complete applications or only a few paths based on our requirements likeÂ below.

http.csrf().disable()

http.csrf().ignoring RequestMatchers("/saveMsg")Thymeleaf has great integration & support with Spring Security to generate a CSRF token. We just need to add the below code in the login HTML form code and Thymeleaf will automatically append the CSRF token for the remaining pages/forms inside the web application,

<input type="hidden" th:name="${_csrf.parameterName}" th:value="${_csrf.token}" />

Enhancements and Best Practices

1. CSRF TokenÂ Storage:Ensure that the CSRF token is securely stored in the userâ€™s session. Spring Security automatically handles this for you, but itâ€™s crucial to emphasize the importance of secure session management.



2. Token Expiry and Regeneration:Implement mechanisms to expire and regenerate CSRF tokens to prevent token reuse and enhance security. Spring Security offers built-in features for token expiration.



3. Custom CSRFÂ Header:Consider using a custom header for CSRF tokens, especially if your application involves multiple technologies or if you want to add an extra layer of security. Spring Security allows customization of the headerÂ name.

http.csrf().headerName("X-CSRF-TOKEN");

4. Strict Content Security PolicyÂ (CSP):Enforce strict Content Security Policy headers on your web pages to mitigate the risk of XSS attacks. This will further secure your application by limiting the sources from which resources can beÂ loaded.

http.headers().contentSecurityPolicy("default-src self");

5. CSRF Token in AJAX Requests:If your application makes AJAX requests, ensure that the CSRF token is included and validated in those requests. Modify your Thymeleaf code accordingly to handle AJAX scenarios.

$.ajax({

 url: /changeEmail,

 type: POST,

 data: {

 email: user@evil.com,

 _csrf: /* CSRF Token value */

 },

 success: function(response) {

 // Handle success

 }

});

6. EducateÂ Users:Educate your users about the importance of not clicking on suspicious links and being cautious while interacting with websites. User awareness is a crucial component in preventing CSRFÂ attacks.



7. Logging and Monitoring:Implement comprehensive logging and monitoring to keep track of suspicious activities and potential CSRF attacks. This will help in identifying and mitigating threats in realÂ time.



SummaryIncorporating CSRF protection is a fundamental step in securing your Spring Boot applications. By following best practices and leveraging the capabilities of Spring Security, you can significantly reduce the risk of CSRF attacks. Remember that security is an ongoing process, and staying informed about the latest security developments is essential to maintaining a robust defense against evolvingÂ threats.

By implementing these additional measures and best practices, you can fortify your applicationâ€™s security posture and provide a safer online experience for your users. Stay vigilant, keep your dependencies up-to-date, and regularly review and enhance your security practices to adapt to emergingÂ threats.

~ By Pramitha Jayasooriya



Contact DetailsFor further information or to discuss potential opportunities, please feel free to connect with me on my professional and social platforms:



LinkedIn: https://www.linkedin.com/in/pramitha-jayasooriya/

GitHub: https://github.com/PramithaMJ

Personal Website: https://pramithamj.meLooking forward to connecting withÂ you!

]]> 